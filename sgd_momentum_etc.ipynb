{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, x = 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.00000048527904,\n",
       " [10,\n",
       "  8.2,\n",
       "  6.76,\n",
       "  5.608,\n",
       "  4.6864,\n",
       "  3.9491199999999997,\n",
       "  3.3592959999999996,\n",
       "  2.8874367999999997,\n",
       "  2.5099494399999998,\n",
       "  2.2079595519999997,\n",
       "  1.9663676415999998,\n",
       "  1.7730941132799998,\n",
       "  1.6184752906239999,\n",
       "  1.4947802324992,\n",
       "  1.3958241859993599,\n",
       "  1.316659348799488,\n",
       "  1.2533274790395903,\n",
       "  1.2026619832316723,\n",
       "  1.1621295865853378,\n",
       "  1.1297036692682703,\n",
       "  1.1037629354146161,\n",
       "  1.0830103483316929,\n",
       "  1.0664082786653544,\n",
       "  1.0531266229322835,\n",
       "  1.0425012983458268,\n",
       "  1.0340010386766614,\n",
       "  1.0272008309413292,\n",
       "  1.0217606647530633,\n",
       "  1.0174085318024506,\n",
       "  1.0139268254419604,\n",
       "  1.0111414603535684,\n",
       "  1.0089131682828547,\n",
       "  1.0071305346262838,\n",
       "  1.005704427701027,\n",
       "  1.0045635421608217,\n",
       "  1.0036508337286574,\n",
       "  1.0029206669829258,\n",
       "  1.0023365335863406,\n",
       "  1.0018692268690725,\n",
       "  1.001495381495258,\n",
       "  1.0011963051962065,\n",
       "  1.0009570441569653,\n",
       "  1.0007656353255723,\n",
       "  1.0006125082604578,\n",
       "  1.0004900066083662,\n",
       "  1.000392005286693,\n",
       "  1.0003136042293543,\n",
       "  1.0002508833834836,\n",
       "  1.0002007067067868,\n",
       "  1.0001605653654295,\n",
       "  1.0001284522923437,\n",
       "  1.000102761833875,\n",
       "  1.0000822094671,\n",
       "  1.00006576757368,\n",
       "  1.0000526140589439,\n",
       "  1.000042091247155,\n",
       "  1.000033672997724,\n",
       "  1.0000269383981792,\n",
       "  1.0000215507185435,\n",
       "  1.0000172405748349,\n",
       "  1.000013792459868,\n",
       "  1.0000110339678945,\n",
       "  1.0000088271743155,\n",
       "  1.0000070617394523,\n",
       "  1.000005649391562,\n",
       "  1.0000045195132494,\n",
       "  1.0000036156105996,\n",
       "  1.0000028924884796,\n",
       "  1.0000023139907837,\n",
       "  1.000001851192627,\n",
       "  1.0000014809541016,\n",
       "  1.0000011847632813,\n",
       "  1.000000947810625,\n",
       "  1.0000007582485,\n",
       "  1.0000006065988,\n",
       "  1.00000048527904],\n",
       " 2.355893258254582e-13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# momentum and optimization\n",
    "## sgd\n",
    "\n",
    "def f_example(x):\n",
    "    return  x ** 2 - 2 * x + 1\n",
    "\n",
    "def f_example_grad(x):\n",
    "    return 2*x - 2\n",
    "f_starting_point = 10\n",
    "f_learning_rate = 0.1\n",
    "\n",
    "# sgd (well, just gd in this case)\n",
    "def sgd(f, f_grad, starting_point, learning_rate=0.1, n_steps = 1000,tol=1e-6):\n",
    "    x = starting_point\n",
    "    x_history = [x]\n",
    "    for i in range(n_steps):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"step {i}, x = {x}\")\n",
    "        x = x - learning_rate * f_grad(x)\n",
    "        x_history.append(x)\n",
    "        if f_grad(x) < tol:\n",
    "            break\n",
    "    return x, x_history,f(x)\n",
    "sgd(f_example, f_example_grad, f_starting_point, f_learning_rate)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, x = 10\n",
      "step 100, x = 6.660915056282735\n",
      "step 200, x = 3.70224434880135\n",
      "step 300, x = 1.1929615531131603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0000003158492414,\n",
       " [10,\n",
       "  9.900000000154321,\n",
       "  9.827837574491483,\n",
       "  9.767608365953636,\n",
       "  9.714271898945608,\n",
       "  9.665491623128577,\n",
       "  9.619966409883652,\n",
       "  9.576887272869936,\n",
       "  9.535712577820595,\n",
       "  9.496059874491365,\n",
       "  9.457648075794495,\n",
       "  9.420264045724519,\n",
       "  9.383742093146953,\n",
       "  9.34795076646291,\n",
       "  9.31278400869608,\n",
       "  9.278155035615493,\n",
       "  9.243991979093996,\n",
       "  9.210234711745446,\n",
       "  9.17683248400642,\n",
       "  9.143742133482023,\n",
       "  9.110926705929456,\n",
       "  9.078354377904802,\n",
       "  9.045997604191458,\n",
       "  9.013832435251633,\n",
       "  8.981837965039041,\n",
       "  8.949995880005462,\n",
       "  8.918290087552606,\n",
       "  8.88670640750581,\n",
       "  8.855232314062118,\n",
       "  8.823856718522984,\n",
       "  8.792569785253749,\n",
       "  8.761362774919947,\n",
       "  8.730227910275643,\n",
       "  8.699158260721271,\n",
       "  8.668147642579665,\n",
       "  8.637190532611116,\n",
       "  8.606281992739442,\n",
       "  8.575417604319474,\n",
       "  8.544593410563115,\n",
       "  8.513805865971973,\n",
       "  8.483051791811757,\n",
       "  8.452328336816107,\n",
       "  8.421632942432678,\n",
       "  8.390963312027418,\n",
       "  8.360317383548466,\n",
       "  8.32969330522234,\n",
       "  8.2990894139147,\n",
       "  8.268504215838103,\n",
       "  8.237936369331575,\n",
       "  8.207384669472729,\n",
       "  8.176848034313807,\n",
       "  8.146325492559201,\n",
       "  8.115816172524514,\n",
       "  8.085319292236564,\n",
       "  8.054834150550509,\n",
       "  8.024360119174759,\n",
       "  7.993896635507015,\n",
       "  7.963443196195741,\n",
       "  7.932999351351058,\n",
       "  7.902564699337468,\n",
       "  7.872138882088259,\n",
       "  7.841721580887974,\n",
       "  7.811312512575103,\n",
       "  7.780911426122267,\n",
       "  7.750518099555671,\n",
       "  7.720132337179647,\n",
       "  7.689753967075639,\n",
       "  7.659382838848169,\n",
       "  7.6290188215931725,\n",
       "  7.59866180206658,\n",
       "  7.568311683033292,\n",
       "  7.537968381778714,\n",
       "  7.507631828766813,\n",
       "  7.477301966430269,\n",
       "  7.446978748079742,\n",
       "  7.416662136920588,\n",
       "  7.386352105166498,\n",
       "  7.356048633240587,\n",
       "  7.325751709055422,\n",
       "  7.295461327364278,\n",
       "  7.265177489176725,\n",
       "  7.2349002012322705,\n",
       "  7.204629475526455,\n",
       "  7.174365328884315,\n",
       "  7.144107782576639,\n",
       "  7.1138568619748845,\n",
       "  7.083612596241042,\n",
       "  7.053375018049082,\n",
       "  7.023144163334956,\n",
       "  6.992920071072418,\n",
       "  6.962702783072208,\n",
       "  6.932492343802359,\n",
       "  6.902288800227636,\n",
       "  6.872092201666284,\n",
       "  6.841902599662459,\n",
       "  6.811720047872866,\n",
       "  6.781544601966265,\n",
       "  6.751376319534668,\n",
       "  6.721215260015123,\n",
       "  6.6910614846211205,\n",
       "  6.660915056282735,\n",
       "  6.630776039594726,\n",
       "  6.6006445007718595,\n",
       "  6.570520507610826,\n",
       "  6.540404129458165,\n",
       "  6.510295437183672,\n",
       "  6.480194503158828,\n",
       "  6.450101401239823,\n",
       "  6.42001620675478,\n",
       "  6.389938996494869,\n",
       "  6.3598698487089695,\n",
       "  6.329808843101635,\n",
       "  6.299756060834088,\n",
       "  6.269711584528054,\n",
       "  6.239675498272204,\n",
       "  6.20964788763106,\n",
       "  6.179628839656188,\n",
       "  6.14961844289955,\n",
       "  6.119616787428882,\n",
       "  6.089623964845002,\n",
       "  6.059640068300942,\n",
       "  6.02966519252283,\n",
       "  5.999699433832441,\n",
       "  5.969742890171359,\n",
       "  5.939795661126702,\n",
       "  5.909857847958353,\n",
       "  5.879929553627672,\n",
       "  5.850010882827654,\n",
       "  5.820101942014505,\n",
       "  5.790202839440633,\n",
       "  5.7603136851890255,\n",
       "  5.730434591209014,\n",
       "  5.700565671353428,\n",
       "  5.6707070414171366,\n",
       "  5.6408588191769855,\n",
       "  5.61102112443314,\n",
       "  5.581194079051853,\n",
       "  5.551377807009669,\n",
       "  5.521572434439098,\n",
       "  5.491778089675772,\n",
       "  5.461994903307122,\n",
       "  5.43222300822261,\n",
       "  5.4024625396655335,\n",
       "  5.372713635286468,\n",
       "  5.342976435198367,\n",
       "  5.313251082033374,\n",
       "  5.283537721001387,\n",
       "  5.25383649995044,\n",
       "  5.224147569428936,\n",
       "  5.194471082749807,\n",
       "  5.1648071960566435,\n",
       "  5.135156068391874,\n",
       "  5.105517861767042,\n",
       "  5.075892741235268,\n",
       "  5.046280874965962,\n",
       "  5.016682434321854,\n",
       "  4.987097593938445,\n",
       "  4.957526531805939,\n",
       "  4.9279694293537615,\n",
       "  4.898426471537746,\n",
       "  4.868897846930095,\n",
       "  4.839383747812206,\n",
       "  4.809884370270472,\n",
       "  4.7803999142951765,\n",
       "  4.75093058388258,\n",
       "  4.721476587140335,\n",
       "  4.692038136396346,\n",
       "  4.662615448311218,\n",
       "  4.6332087439944125,\n",
       "  4.603818249124276,\n",
       "  4.57444419407208,\n",
       "  4.545086814030232,\n",
       "  4.51574634914483,\n",
       "  4.486423044652724,\n",
       "  4.457117151023269,\n",
       "  4.4278289241049675,\n",
       "  4.398558625277186,\n",
       "  4.369306521607165,\n",
       "  4.340072886012536,\n",
       "  4.310857997429574,\n",
       "  4.281662140987424,\n",
       "  4.252485608188561,\n",
       "  4.22332869709573,\n",
       "  4.194191712525663,\n",
       "  4.165074966249846,\n",
       "  4.135978777202644,\n",
       "  4.106903471697115,\n",
       "  4.077849383648831,\n",
       "  4.04881685480807,\n",
       "  4.019806235000743,\n",
       "  3.9908178823784524,\n",
       "  3.961852163678077,\n",
       "  3.9329094544913294,\n",
       "  3.903990139544729,\n",
       "  3.8750946129904635,\n",
       "  3.8462232787086497,\n",
       "  3.817376550621512,\n",
       "  3.7885548530200372,\n",
       "  3.759758620903693,\n",
       "  3.730988300333819,\n",
       "  3.70224434880135,\n",
       "  3.673527235609546,\n",
       "  3.6448374422724643,\n",
       "  3.6161754629299216,\n",
       "  3.5875418047797627,\n",
       "  3.55893698852828,\n",
       "  3.5303615488596827,\n",
       "  3.5018160349255623,\n",
       "  3.473301010855359,\n",
       "  3.444817056288887,\n",
       "  3.416364766932038,\n",
       "  3.3879447551368504,\n",
       "  3.359557650507197,\n",
       "  3.3312041005314197,\n",
       "  3.3028847712433156,\n",
       "  3.2746003479129686,\n",
       "  3.246351535768999,\n",
       "  3.2181390607539093,\n",
       "  3.1899636703142966,\n",
       "  3.1618261342278187,\n",
       "  3.133727245468905,\n",
       "  3.1056678211153392,\n",
       "  3.0776487032979554,\n",
       "  3.049670760195849,\n",
       "  3.021734887079636,\n",
       "  2.993842007405462,\n",
       "  2.965993073962633,\n",
       "  2.9381890700779185,\n",
       "  2.910431010879777,\n",
       "  2.8827199446259613,\n",
       "  2.8550569540981754,\n",
       "  2.8274431580677106,\n",
       "  2.799879712836226,\n",
       "  2.7723678138561163,\n",
       "  2.7449086974352137,\n",
       "  2.717503642530856,\n",
       "  2.690153972638718,\n",
       "  2.662861057782135,\n",
       "  2.635626316608039,\n",
       "  2.60845121859604,\n",
       "  2.5813372863876087,\n",
       "  2.5542860982427977,\n",
       "  2.527299290632421,\n",
       "  2.5003785609741516,\n",
       "  2.4735256705215636,\n",
       "  2.4467424474157458,\n",
       "  2.420030789909754,\n",
       "  2.3933926697768677,\n",
       "  2.366830135914323,\n",
       "  2.3403453181549883,\n",
       "  2.313940431300249,\n",
       "  2.2876177793882455,\n",
       "  2.2613797602125105,\n",
       "  2.2352288701070235,\n",
       "  2.2091677090146944,\n",
       "  2.1831989858573535,\n",
       "  2.1573255242264087,\n",
       "  2.1315502684144647,\n",
       "  2.1058762898093684,\n",
       "  2.0803067936733153,\n",
       "  2.0548451263308616,\n",
       "  2.0294947827908576,\n",
       "  2.004259414828493,\n",
       "  1.9791428395547446,\n",
       "  1.9541490485015334,\n",
       "  1.9292822172518045,\n",
       "  1.9045467156444391,\n",
       "  1.8799471185843828,\n",
       "  1.8554882174885101,\n",
       "  1.8311750323974607,\n",
       "  1.8070128247828474,\n",
       "  1.7830071110777124,\n",
       "  1.7591636769557046,\n",
       "  1.7354885923809535,\n",
       "  1.7119882274457607,\n",
       "  1.688669269006696,\n",
       "  1.6655387381210873,\n",
       "  1.6426040082747728,\n",
       "  1.6198728243777916,\n",
       "  1.5973533224867686,\n",
       "  1.5750540501903385,\n",
       "  1.5529839875661298,\n",
       "  1.5311525685835528,\n",
       "  1.509569702784654,\n",
       "  1.4882457970242218,\n",
       "  1.4671917769885308,\n",
       "  1.446419108137812,\n",
       "  1.425939815628733,\n",
       "  1.405766502667755,\n",
       "  1.3859123666219517,\n",
       "  1.3663912120685506,\n",
       "  1.3472174597960087,\n",
       "  1.3284061505762563,\n",
       "  1.3099729423089088,\n",
       "  1.2919340988940602,\n",
       "  1.274306468922843,\n",
       "  1.2571074519889784,\n",
       "  1.2403549501284037,\n",
       "  1.224067301600927,\n",
       "  1.2082631939571837,\n",
       "  1.1929615531131603,\n",
       "  1.1781814050197845,\n",
       "  1.163941706513606,\n",
       "  1.1502611421246252,\n",
       "  1.1371578840675893,\n",
       "  1.1246493134302735,\n",
       "  1.1127517017758577,\n",
       "  1.101479854069879,\n",
       "  1.090846716079629,\n",
       "  1.080862952192968,\n",
       "  1.071536502924561,\n",
       "  1.0628721351009125,\n",
       "  1.0548710016223506,\n",
       "  1.0475302314607597,\n",
       "  1.040842573730669,\n",
       "  1.0347961217526573,\n",
       "  1.0293741434694672,\n",
       "  1.0245550428857295,\n",
       "  1.020312473038012,\n",
       "  1.0166156142632272,\n",
       "  1.013429622440236,\n",
       "  1.010716241003716,\n",
       "  1.0084345587674597,\n",
       "  1.0065418840763614,\n",
       "  1.0049946957553033,\n",
       "  1.0037496238885728,\n",
       "  1.0027644095634163,\n",
       "  1.0019987929090273,\n",
       "  1.0014152831945289,\n",
       "  1.0009797731101635,\n",
       "  1.000661970926482,\n",
       "  1.0004356379440893,\n",
       "  1.000278633202057,\n",
       "  1.0001727813748036,\n",
       "  1.000103591750395,\n",
       "  1.000059864937296,\n",
       "  1.0000332286427236,\n",
       "  1.00001764415612,\n",
       "  1.0000089212861096,\n",
       "  1.0000042722322908,\n",
       "  1.000001925462194,\n",
       "  1.0000008105793141,\n",
       "  1.0000003158492414],\n",
       " 9.969802761133906e-14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# sgd (well, just gd in this case)\n",
    "def adagrad(f, f_grad, starting_point, learning_rate=0.1,momentum_parameter=0.9, n_steps = 1000,tol=1e-6):\n",
    "    x = starting_point\n",
    "    x_history = [x]\n",
    "    g = 0\n",
    "    for i in range(n_steps):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"step {i}, x = {x}\")\n",
    "        g = 0.9*g + f_grad(x)**2\n",
    "        x = x - learning_rate / np.sqrt(g + tol) * f_grad(x)## we scale down the by the total magnitude of gradient updates so far\n",
    "        x_history.append(x)\n",
    "        if f_grad(x) < tol:\n",
    "            break\n",
    "    return x, x_history,f(x)\n",
    "adagrad(f_example, f_example_grad, f_starting_point, f_learning_rate)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, x = 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0000011333114243,\n",
       " [10,\n",
       "  8.2,\n",
       "  5.4639999999999995,\n",
       "  2.60128,\n",
       "  0.21986560000000033,\n",
       "  -1.3387258879999997,\n",
       "  -1.9931665817599997,\n",
       "  -1.8657305649151996,\n",
       "  -1.2008305198039035,\n",
       "  -0.28193638336298965,\n",
       "  0.6360546715470663,\n",
       "  1.3697972967728933,\n",
       "  1.8241325275809102,\n",
       "  1.9864273882465002,\n",
       "  1.905994210276425,\n",
       "  1.6668834800826857,\n",
       "  1.3613470583266563,\n",
       "  1.069091422996984,\n",
       "  0.8448490809602229,\n",
       "  0.7144247785017105,\n",
       "  0.6776343250312394,\n",
       "  0.7156183335262524,\n",
       "  0.7998431529374113,\n",
       "  0.9005163923259634,\n",
       "  0.9928978462205282,\n",
       "  1.0608329237805094,\n",
       "  1.097579594867594,\n",
       "  1.104521279076776,\n",
       "  1.088615035892032,\n",
       "  1.0594395336206097,\n",
       "  1.0265452652610638,\n",
       "  0.9975523389899781,\n",
       "  0.9771669642768007,\n",
       "  0.9670561016279529,\n",
       "  0.9663650601951919,\n",
       "  0.9725944983245656,\n",
       "  0.9825607941128015,\n",
       "  0.993224368257771,\n",
       "  1.002257267990595,\n",
       "  1.0083095022001092,\n",
       "  1.0110052103909375,\n",
       "  1.0107450782101464,\n",
       "  1.0084087673979476,\n",
       "  1.005044870133575,\n",
       "  1.0016138900765117,\n",
       "  0.9988208064201237,\n",
       "  0.9970456249034997,\n",
       "  0.9963583692308304,\n",
       "  0.9965918713003424,\n",
       "  0.9974416185303226,\n",
       "  0.9985651128298438,\n",
       "  0.9996610061595304,\n",
       "  1.0005178481249986,\n",
       "  1.001031204715136,\n",
       "  1.0011945805170077,\n",
       "  1.0010732949909538,\n",
       "  1.0007713104140041,\n",
       "  1.0003996194357996,\n",
       "  1.0000520780443325,\n",
       "  0.9997914326336096,\n",
       "  0.9996454814111672,\n",
       "  0.9996113002487752,\n",
       "  0.9996644297620979,\n",
       "  0.9997697970592707,\n",
       "  0.999891702101381,\n",
       "  1.0000011333114243],\n",
       " 1.284305994886381e-12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding nestorov momentum here...\n",
    "def nesterov_momentum(f, f_grad, starting_point, learning_rate=0.1, momentum=0.9, n_steps=1000, tol=1e-5):\n",
    "    x = starting_point\n",
    "    v = 0.0\n",
    "    x_history = [x]\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"step {i}, x = {x}\")\n",
    "\n",
    "        # Nesterov look-ahead point interesting...\n",
    "        x_lookahead = x + momentum * v\n",
    "        grad = f_grad(x_lookahead)\n",
    "\n",
    "        # Update velocity and position\n",
    "        v = momentum * v - learning_rate * grad\n",
    "        x = x + v\n",
    "        x_history.append(x)\n",
    "\n",
    "        if abs(grad) < tol:\n",
    "            break\n",
    "\n",
    "    return x, x_history, f(x)\n",
    "\n",
    "nesterov_momentum(f_example, f_example_grad, f_starting_point, f_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
